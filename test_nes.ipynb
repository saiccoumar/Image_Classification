{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model Architectures\n",
    "Custom Torch Models need to be instantiated for evaluation. The model_architectures.py file contains the model architectures so we can abstract it and focus only on the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n",
      "['BasicBlock', 'DataLoader', 'F', 'Load', 'ResNetCIFAR', 'ResNetMNIST', 'ResnetSVHN', 'TensorDataset', 'Tester', 'Visualizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'cifar_directory', 'conv3x3', 'current_directory', 'device', 'mnist_directory', 'nn', 'np', 'os', 'pd', 'pickle', 'plt', 'scipy', 'svhn_directory', 'torch']\n"
     ]
    }
   ],
   "source": [
    "from model_architectures import *\n",
    "import model_architectures\n",
    "from attacks import * \n",
    "# Print available classes to verify our model architectures were imported\n",
    "print(dir(model_architectures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model Weights\n",
    "Using our model artifacts we load the weights back into the model so we have our pre-trained models to test our perturbations against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model = ResNetMNIST(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=True).to(device)\n",
    "cifar_resnet_model = ResNetCIFAR(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "svhn_resnet_model = ResnetSVHN(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "\n",
    "#add map_location=torch.device('cpu') if running locally and ur not sai lol\n",
    "device = 'cuda'\n",
    "# mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\", map_location=torch.device(device)))\n",
    "# cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\", map_location=torch.device(device)))\n",
    "# svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\",map_location=torch.device(device)))\n",
    "mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\"))\n",
    "cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\"))\n",
    "svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetSVHN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set models to evaluation mode\n",
    "mnist_resnet_model.eval()\n",
    "cifar_resnet_model.eval()\n",
    "svhn_resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "loader = Load()\n",
    "mnist_test_images, mnist_test_labels = loader.load_mnist_test_images()\n",
    "cifar10_test_images, cifar10_test_labels = loader.load_cifar10_test_images()\n",
    "svhn_test_images, svhn_test_labels = loader.load_svhn_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_mnist = loader.convert_mnist_numpy_to_tensor(mnist_test_images[:256], mnist_test_labels[:256])\n",
    "test_loader_cifar10 = loader.convert_cifar10_numpy_to_tensor(cifar10_test_images[:256], cifar10_test_labels[:256])\n",
    "test_loader_svhn = loader.convert_svhn_numpy_to_tensor(svhn_test_images[:256], svhn_test_labels[:256])\n",
    "tester = Tester()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NES-FD\n",
    "NES is a score-based black box algorithm for adversarial attacks. It works almost identically to PGD but estimates the gradient using Natural Evolution Strategies rather than extracting it directly from the model. The estimation strategy is quite simple. NES approximates gradients by iteratively perturbing input images with random noise and observing the resulting changes in the model's predictions. This process mimics natural selection, where promising perturbations that lead to higher misclassification probabilities are amplified in subsequent iterations. By accumulating these perturbation-induced changes, NES effectively estimates gradients without requiring direct access to the model's internal parameters, making it particularly suitable for black-box adversarial attack scenarios. \n",
    "\n",
    "For one iteration of estimation:\n",
    "\n",
    "$$\n",
    "u_i \\leftarrow \\mathcal{N}(0_N, I_{N \\times N})\n",
    "$$\n",
    "$$\n",
    "g \\leftarrow g + P(y|x + \\sigma \\cdot u_i) \\cdot u_i\n",
    "$$\n",
    "$$\n",
    "g \\leftarrow g - P(y|x - \\sigma \\cdot u_i) \\cdot u_i\n",
    "$$\n",
    "\n",
    "NES uses uses $L^∞$ Norm Perturbations similar to PGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nes(model, test_loader, epsilon, alpha):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    adv_examples = []\n",
    "    batch = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        batch += 1\n",
    "        print(f\"Batch: {batch}, Epsilon: {epsilon}, Correct: {correct}\")\n",
    "        for image, label in zip(images, labels):\n",
    "            image = image.unsqueeze(0)\n",
    "            label = label.unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            output, _ = model(image)\n",
    "\n",
    "            _, init_pred = torch.max(output.data, 1)\n",
    "\n",
    "            if not torch.equal(init_pred, label):\n",
    "                total +=1 \n",
    "                continue\n",
    "            \n",
    "            \n",
    "\n",
    "            output_final, perturbed_data = nes_attack(image, model, init_pred, output, epsilon, alpha)\n",
    "            _, final_pred = torch.max(output_final.data, 1)\n",
    "            if torch.equal(final_pred, label):\n",
    "                correct += 1\n",
    "                if epsilon == 0 and len(adv_examples) < 5:\n",
    "                    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "            else:\n",
    "                # Save some adv examples for visualization later\n",
    "            \n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "            total +=1 \n",
    "            print(f\"{correct}/{total}\")\n",
    "            \n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {total} = {accuracy}\")\n",
    "    return accuracy, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Epsilon: 8, Correct: 0\n",
      "7 7 15.285808563232422  ,diff:  92.92862701416016\n",
      "7 7 15.144009590148926  ,diff:  107.37252807617188\n",
      "7 7 15.423689842224121  ,diff:  101.94356536865234\n",
      "7 7 15.206236839294434  ,diff:  113.7379150390625\n",
      "7 7 15.621082305908203  ,diff:  87.30177307128906\n",
      "7 7 15.048015594482422  ,diff:  109.30345153808594\n",
      "7 7 14.769824028015137  ,diff:  69.95709228515625\n",
      "7 7 15.072145462036133  ,diff:  93.31088256835938\n",
      "7 7 15.208332061767578  ,diff:  87.58024597167969\n",
      "7 7 15.33874225616455  ,diff:  100.76663208007812\n",
      "7 7 15.476858139038086  ,diff:  98.5856704711914\n",
      "7 7 15.302431106567383  ,diff:  94.63262939453125\n",
      "7 7 15.285634994506836  ,diff:  94.47023010253906\n",
      "7 7 15.167536735534668  ,diff:  89.67774200439453\n",
      "7 7 15.061856269836426  ,diff:  104.27871704101562\n",
      "7 7 15.006876945495605  ,diff:  88.291015625\n",
      "7 7 15.42301082611084  ,diff:  117.4801254272461\n",
      "7 7 15.205526351928711  ,diff:  107.93376159667969\n",
      "7 7 14.926629066467285  ,diff:  103.12708282470703\n",
      "7 7 14.941601753234863  ,diff:  109.88874053955078\n",
      "7 7 15.153901100158691  ,diff:  91.41029357910156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# MNIST\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy, examples \u001b[38;5;241m=\u001b[39m \u001b[43mtest_nes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist_resnet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36mtest_nes\u001b[1;34m(model, test_loader, epsilon, alpha)\u001b[0m\n\u001b[0;32m     21\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m output_final, perturbed_data \u001b[38;5;241m=\u001b[39m \u001b[43mnes_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m _, final_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output_final\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(final_pred, label):\n",
      "File \u001b[1;32mc:\\Users\\Sai\\Work\\cs490\\attacks.py:242\u001b[0m, in \u001b[0;36mnes_attack\u001b[1;34m(image, model, init_pred, init_labels, epsilon, alpha, max_iterations)\u001b[0m\n\u001b[0;32m    240\u001b[0m sign_data_grad_actual \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msign()\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Extract gradient\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m sign_data_grad \u001b[38;5;241m=\u001b[39m \u001b[43mnes_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msign_data_grad_actual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperturbed_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m sign_data_grad \u001b[38;5;241m=\u001b[39m sign_data_grad\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# print(torch.norm((sign_data_grad_actual - sign_data_grad).view(-1)))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sai\\Work\\cs490\\attacks.py:209\u001b[0m, in \u001b[0;36mnes_attack.<locals>.nes_estimation\u001b[1;34m(sign_data_grad_actual, model, label_actual, sigma, n, image)\u001b[0m\n\u001b[0;32m    206\u001b[0m ui \u001b[38;5;241m=\u001b[39m create_multivariate_gaussian(torch\u001b[38;5;241m.\u001b[39mzeros(N), torch\u001b[38;5;241m.\u001b[39meye(N))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    207\u001b[0m ui \u001b[38;5;241m=\u001b[39m ui\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 209\u001b[0m p_plus \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mui\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_actual\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m p_minus \u001b[38;5;241m=\u001b[39m model(image \u001b[38;5;241m-\u001b[39m sigma \u001b[38;5;241m*\u001b[39m ui)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][label_actual]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    212\u001b[0m g \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_plus \u001b[38;5;241m*\u001b[39m ui\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "accuracy, examples = test_nes(mnist_resnet_model, test_loader_mnist, 8, 0.01 )\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (0,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# MNIST Viewer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(examples)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(8, 10))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# for j in range(100):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     plt.subplot(10, 10, j + 1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     plt.imshow(ex, cmap=\"gray\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# plt.tight_layout()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\pyplot.py:2695\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2689\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2691\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2692\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2693\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2694\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2695\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2697\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2701\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2702\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2703\u001b[0m     sci(__ret)\n\u001b[0;32m   2704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py:1459\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1462\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1463\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5657\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5658\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   5659\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   5660\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5661\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5662\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5663\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5665\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5666\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5668\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    711\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (0,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST Viewer\n",
    "print(examples)\n",
    "plt.imshow(examples)\n",
    "\n",
    "# plt.figure(figsize=(8, 10))\n",
    "# for j in range(100):\n",
    "#     plt.subplot(10, 10, j + 1)\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     orig, adv, ex = examples[j]\n",
    "#     plt.title(f\"{orig} -> {adv}\")\n",
    "#     plt.imshow(ex, cmap=\"gray\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
